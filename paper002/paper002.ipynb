{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3657d4",
   "metadata": {},
   "source": [
    "# Apple Detection - Paper Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593f537",
   "metadata": {},
   "source": [
    "## Comparison between real and synthetic point clouds of apple trees \n",
    "\n",
    "To compare the two types of point clouds are going to be taken the point clouds got from the two different protocols, LowRes and HighRes, on the two types of scans, real and synthetic. The number of points per experiment (Scan of a row of 5 trees)  is going to be avaranged to have a global view of the differences in size of the point clouds.<br> \n",
    "\n",
    "<div class=\"img-container\"> <!-- Block parent element -->\n",
    "    <figure>\n",
    "      <img src=\"images/treeSchema.png\" alt=\"TreeSchema\" style=\"width:500px;height:200px;\">\n",
    "      <figcaption>Fig.1 - Point density estimation schema.</figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "To evaluate that the synthetic sensor was correctly parametrised, it was estimated the density of points per experiment and per tree following the schema of figure 1. In this schema <em>R</em> is the maximum radius that encapsulate each tree, <em>c</em> is the height of the tree, and <em>W</em> and <em>H</em> are the maximum height and width occupied by a row of 5 trees. To estimate the density of points per tree, the trees were encapsulated in a cylinder and from this was applied the equation \\ref{eq1}. <br>\n",
    "\n",
    "\\begin{equation} \n",
    "T_{d} = \\frac{N_{points}} {\\pi R^{2}c}\n",
    "\\label{eq1} \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "The density of the experiment was defined in equation \\ref{eq2}\n",
    "\n",
    "\\begin{equation} \n",
    "T_{d} = \\frac{N_{points}} {WH \\max{ (\\mathbf{c}) }}\n",
    "\\label{eq2} \\tag{2}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f305491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"-> Found real scans: %d\" %(len(lst_files_real)))\\nprint(\"-> Found synthetic files: \\n   -> J001RW0: %i\\n   -> J001RW1: %i\\n   -> J001RW2: %i\" %(len(lst_file_s_j001_rw0),len(lst_file_s_j001_rw1), len(lst_file_s_j001_rw2)))\\n# Get the density and few coordianted points that enclose the geometry \\ndictList_real, biggestGeom_real     = pcD.pointCloud_generalDescription(lst_files_real, verbose=True)\\ndictList_j001_rw0, biggest_j001_rw0 = pcD.pointCloud_generalDescription(lst_file_s_j001_rw0, verbose=True)\\ndictList_j001_rw1, biggest_j001_rw1 = pcD.pointCloud_generalDescription(lst_file_s_j001_rw1, verbose=True)\\ndictList_j001_rw2, biggest_j001_rw2 = pcD.pointCloud_generalDescription(lst_file_s_j001_rw2, verbose=True)\\n#  Order the elements by volume \\nprint(\"-> Sorting\")\\nsorted_vol_realScan = pcD.sort_tree_by(dictList_real)\\nsorted_j001_rw0     = pcD.sort_tree_by(dictList_j001_rw0)\\nsorted_j001_rw1     = pcD.sort_tree_by(dictList_j001_rw1)\\nsorted_j001_rw2     = pcD.sort_tree_by(dictList_j001_rw2)\\nprint(\"  -> OK\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import glob \n",
    "from pointCloudsDescriptor import PointCloudFEvaluator\n",
    "# Ray width \n",
    "pcD =  PointCloudFEvaluator()\n",
    "# Path to the data \n",
    "base2synthetic = \"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/\"\n",
    "path2synthetic_j001_rw0 = os.path.join(base2synthetic, \"jitter001_rw0/special_split_featured_apples/susbset_at_0.8/\")\n",
    "path2synthetic_j001_rw1 = os.path.join(base2synthetic, \"jitter001_rw1/special_split_featured_apples/susbset_at_0.8/\")\n",
    "path2synthetic_j001_rw2 = os.path.join(base2synthetic, \"jitter001_rw2/special_split_featured_apples/susbset_at_0.8/\")\n",
    "\n",
    "path2real      = \"/media/juan/jprb/PhD_2020_2023/Data/annotated_data_realTrees/\" \n",
    "# List of files\n",
    "\n",
    "lst_files_real = glob.glob(os.path.join(path2real, \"*.txt\"))\n",
    "lst_file_s_j001_rw0 = glob.glob(os.path.join(path2synthetic_j001_rw0, \"*.txt\"))\n",
    "lst_file_s_j001_rw1 = glob.glob(os.path.join(path2synthetic_j001_rw1, \"*.txt\"))\n",
    "lst_file_s_j001_rw2 = glob.glob(os.path.join(path2synthetic_j001_rw2, \"*.txt\"))\n",
    "\"\"\"\n",
    "print(\"-> Found real scans: %d\" %(len(lst_files_real)))\n",
    "print(\"-> Found synthetic files: \\n   -> J001RW0: %i\\n\\\n",
    "   -> J001RW1: %i\\n\\\n",
    "   -> J001RW2: %i\" %(len(lst_file_s_j001_rw0),len(lst_file_s_j001_rw1), len(lst_file_s_j001_rw2)))\n",
    "# Get the density and few coordianted points that enclose the geometry \n",
    "dictList_real, biggestGeom_real     = pcD.pointCloud_generalDescription(lst_files_real, verbose=True)\n",
    "dictList_j001_rw0, biggest_j001_rw0 = pcD.pointCloud_generalDescription(lst_file_s_j001_rw0, verbose=True)\n",
    "dictList_j001_rw1, biggest_j001_rw1 = pcD.pointCloud_generalDescription(lst_file_s_j001_rw1, verbose=True)\n",
    "dictList_j001_rw2, biggest_j001_rw2 = pcD.pointCloud_generalDescription(lst_file_s_j001_rw2, verbose=True)\n",
    "#  Order the elements by volume \n",
    "print(\"-> Sorting\")\n",
    "sorted_vol_realScan = pcD.sort_tree_by(dictList_real)\n",
    "sorted_j001_rw0     = pcD.sort_tree_by(dictList_j001_rw0)\n",
    "sorted_j001_rw1     = pcD.sort_tree_by(dictList_j001_rw1)\n",
    "sorted_j001_rw2     = pcD.sort_tree_by(dictList_j001_rw2)\n",
    "print(\"  -> OK\")\n",
    "\"\"\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f41445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume Plots ray width -- biggest 10 trees \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "# Plots \n",
    "volReal2plot = []\n",
    "syntheticDict = {\"j001rw0\":[],\n",
    "                 \"j001rw1\":[], \n",
    "                 \"j001rw2\":[]}\n",
    "syntheticDictAll = {\"j001rw0\":[],\n",
    "                 \"j001rw1\":[], \n",
    "                 \"j001rw2\":[]}\n",
    "trees = []\n",
    "#\n",
    "for idx, (realTreeScanA, j001rw0, j001rw1, j001rw2) in enumerate( zip(sorted_vol_realScan, sorted_j001_rw0[-10:], sorted_j001_rw1[-10:], sorted_j001_rw2[-10:])):\n",
    "    volReal2plot.append(realTreeScanA[\"volume\"])\n",
    "    syntheticDict[\"j001rw0\"].append(j001rw0[\"volume\"])\n",
    "    syntheticDict[\"j001rw1\"].append(j001rw1[\"volume\"])\n",
    "    syntheticDict[\"j001rw2\"].append(j001rw2[\"volume\"])\n",
    "    trees.append(idx)    \n",
    "# All synthetic trees \n",
    "for idx, (j001rw0, j001rw1, j001rw2) in enumerate( zip(sorted_j001_rw0, sorted_j001_rw1, sorted_j001_rw2)):\n",
    "    syntheticDictAll[\"j001rw0\"].append(j001rw0[\"volume\"])\n",
    "    syntheticDictAll[\"j001rw1\"].append(j001rw1[\"volume\"])\n",
    "    syntheticDictAll[\"j001rw2\"].append(j001rw2[\"volume\"])   \n",
    "#\n",
    "plt.plot(trees, volReal2plot, \"bo-\")\n",
    "plt.plot(trees, syntheticDict[\"j001rw0\"], \"ro-\")\n",
    "plt.plot(trees, syntheticDict[\"j001rw1\"], \"co-\")\n",
    "plt.plot(trees, syntheticDict[\"j001rw2\"], \"mo-\")\n",
    "plt.plot()\n",
    "plt.xlabel(\"tree\")\n",
    "plt.ylabel(\"Volume\")\n",
    "plt.legend([\"Real-Scan\", \"J001RW0\", \"J001RW1\", \"J001RW2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# Mean Volume of All the experiment -- Ray width \n",
    "j001rw0_mean = np.mean(np.array(syntheticDictAll[\"j001rw0\"]))\n",
    "j001rw1_mean = np.mean(np.array(syntheticDictAll[\"j001rw1\"]))\n",
    "j001rw2_mean = np.mean(np.array(syntheticDictAll[\"j001rw2\"]))\n",
    "# Real \n",
    "vol10rt_mean = np.mean(np.array(volReal2plot))\n",
    "# Print \n",
    "print(j001rw0_mean, j001rw1_mean, j001rw2_mean, vol10rt_mean)\n",
    "\n",
    "plt.plot([0.04, 0.08, 0.11], [vol10rt_mean, vol10rt_mean, vol10rt_mean], \"b--\")\n",
    "plt.plot([0.04, 0.08, 0.11], [j001rw0_mean, j001rw1_mean, j001rw2_mean], \"ro-\")\n",
    "plt.legend([\"AVG-Volumen-Synthetic-RW\", \"AVG-Volume-real\"])\n",
    "plt.xlabel(\"Ray width[Â°]\")\n",
    "plt.ylabel(\"Volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631948d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biggest 10 trees - Density and comparison with the real ones  - Ray width \n",
    "import numpy as np \n",
    "# Ray Width density plots\n",
    "lstOfLst = [lst_files_real, lst_file_s_j001_rw0, lst_file_s_j001_rw1, lst_file_s_j001_rw2]\n",
    "dic2keep = {}\n",
    "dic2keep_ps = {}\n",
    "\n",
    "for idx, singlLst in enumerate(lstOfLst):\n",
    "    for file2load in singlLst:\n",
    "        pc2load = np.loadtxt(file2load)\n",
    "        a_volume = pcD.get_volume(pc2load)\n",
    "        d = pc2load.shape[0]/a_volume\n",
    "        pointSpacing = pcD.get_point_sparcing(pc2load, d)\n",
    "        if(idx not in dic2keep.keys()):\n",
    "            dic2keep[idx] = [d]\n",
    "            dic2keep_ps[idx] = [pointSpacing]\n",
    "        else:\n",
    "            dic2keep[idx].append(d)\n",
    "            dic2keep_ps[idx].append(pointSpacing)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4962b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List[1/4] | Loading[1/10]\r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2463782 is out of bounds for axis 0 with size 2463782",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9edb19130985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"List[%i/%i] | Loading[%i/%i]\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstOfLst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinglLst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinglLst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpc2load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile2load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_point_cloud_avg_density\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc2load\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#pointSpacing = pcD.get_point_sparcing(pc2load, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic2keep2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/76db166d-2c59-4b55-9a91-19935005e2ef/repos/fruitTree2020/code/paper002Notebook/pointCloudsDescriptor.py\u001b[0m in \u001b[0;36mget_point_cloud_avg_density\u001b[0;34m(self, pc, radius)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mlstDens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mnPts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkdt_rep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_radius\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mlstDens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnPts\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlstDens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2463782 is out of bounds for axis 0 with size 2463782"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# Ray Width density plots\n",
    "lstOfLst = [lst_files_real, lst_file_s_j001_rw0, lst_file_s_j001_rw1, lst_file_s_j001_rw2]\n",
    "# Density with the avg of several spheres \n",
    "dic2keep2 = {}\n",
    "dic2keep_ps2 = {}\n",
    "\n",
    "for idx, singlLst in enumerate(lstOfLst):\n",
    "    for idx2, file2load in enumerate(singlLst):\n",
    "        print(\"List[%i/%i] | Loading[%i/%i]\"%(idx+1, len(lstOfLst), idx2+1, len(singlLst)), end=\"\\r\" if idx2<len(singlLst)-1 else \"\\n\" )\n",
    "        pc2load = np.loadtxt(file2load)\n",
    "        d = pcD.get_point_cloud_avg_density(pc2load[:,0:3])\n",
    "        #pointSpacing = pcD.get_point_sparcing(pc2load, d)\n",
    "        if(idx not in dic2keep2.keys()):\n",
    "            dic2keep2[idx] = []\n",
    "            dic2keep2[idx].append(d)\n",
    "            #dic2keep_ps2[idx] = [pointSpacing]\n",
    "        else:\n",
    "            dic2keep2[idx] = dic2keep2[idx] + d\n",
    "            #dic2keep_ps2[idx].append(pointSpacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot RW last 10 trees -- Ray width \n",
    "from algorithm import inserting_sort\n",
    "\n",
    "d_real = inserting_sort(dic2keep[0])\n",
    "d_s_j001rw0 = inserting_sort(dic2keep2[1])\n",
    "d_s_j001rw1 = inserting_sort(dic2keep2[2])\n",
    "d_s_j001rw2 = inserting_sort(dic2keep2[3])\n",
    "#\n",
    "plt.plot(trees, d_real, \"bo-\")\n",
    "plt.plot(trees, d_s_j001rw0[-10:], \"ro-\")\n",
    "plt.plot(trees, d_s_j001rw1[-10:], \"co-\")\n",
    "plt.plot(trees, d_s_j001rw2[-10:], \"mo-\")\n",
    "plt.xlabel(\"tree\")\n",
    "plt.ylabel(\"Density [Pts/m^3]\")\n",
    "plt.legend([\"Real-Scan\", \"J001RW0\", \"J001RW2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of the density -- Ray Width \n",
    "avg_d_real = np.mean(np.array(dic2keep2[0]))\n",
    "avg_d_s_j001_rw0 = np.mean(np.array(dic2keep2[1]))\n",
    "avg_d_s_j001_rw1 = np.mean(np.array(dic2keep2[2]))\n",
    "avg_d_s_j001_rw2 = np.mean(np.array(dic2keep2[3]))\n",
    "base_r_w = [0.04, 0.08, 0.11] # Ray width angle \n",
    "vavg_r_w = [ avg_d_real for _ in range(3) ]\n",
    "\n",
    "print(avg_d_s_j001_rw0, avg_d_s_j001_rw1, avg_d_s_j001_rw2, avg_d_real)\n",
    "\n",
    "plt.plot(base_r_w, vavg_r_w, \"b--\")\n",
    "plt.plot(base_r_w, [avg_d_s_j001_rw0, avg_d_s_j001_rw1, avg_d_s_j001_rw2], \"ro-\")\n",
    "plt.xlabel(\"Ray width\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend([\"AVG-PointDensity-Real\",  \"AVG-PointDensity-Synthetic-RW\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61659124",
   "metadata": {},
   "source": [
    "Another element that could be use full to describe the general behaviour of the point cloud is the point spacing <em>PS<em>. The point spacing is defined as the linear units per point. See equation \\ref{eq3}\n",
    "    \n",
    "\\begin{equation} \n",
    "PS = \\sqrt{ \\frac{1}{Point Density} }\n",
    "\\label{eq3} \\tag{3}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff707b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray width \n",
    "ps_real = inserting_sort(dic2keep2[0])\n",
    "ps_s_j001rw0 = inserting_sort(dic2keep2[1])\n",
    "ps_s_j001rw1 = inserting_sort(dic2keep2[2])\n",
    "ps_s_j001rw2 = inserting_sort(dic2keep2[3])\n",
    "#\n",
    "plt.plot(trees, ps_real, \"bo-\")\n",
    "plt.plot(trees, ps_s_j001rw0[-10:], \"ro-\")\n",
    "plt.plot(trees, ps_s_j001rw1[-10:], \"co-\")\n",
    "plt.plot(trees, d_s_j001rw2[-10:], \"mo-\")\n",
    "plt.xlabel(\"tree\")\n",
    "plt.ylabel(\"Point Spacing\")\n",
    "plt.legend([\"Real-Scan\", \"J001RW0\", \"J001RW1\", \"J001RW2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385dcace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob \n",
    "# JITTER \n",
    "path_base = \"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp\"\n",
    "path_real_noFloor = \"/media/juan/jprb/PhD_2020_2023/Data/data2fruithunter/annotated_trees_withRadiometricFeatures/\"\n",
    "lst_realNoFl = glob.glob(os.path.join(path_real_noFloor, \"*.txt\"))\n",
    "lst_2j001RW0 = glob.glob(os.path.join(path_base, \"jitter001_rw0/all_splited/*.txt\"))\n",
    "lst_2j01RW0 = glob.glob(os.path.join(path_base, \"jitter01_rw0/all_splitted/*.txt\"))\n",
    "lst_2j02RW0 = glob.glob(os.path.join(path_base, \"jitter02_rw0/all_splitted/*.txt\"))\n",
    "lst_2j03RW0 = glob.glob(os.path.join(path_base, \"jitter03_rw0/all_splitted/*.txt\"))\n",
    "lst_2j04RW0 = glob.glob(os.path.join(path_base, \"jitter04_rw0/all_splitted/*.txt\"))\n",
    "lst_2j05RW0 = glob.glob(os.path.join(path_base, \"jitter05_rw0/all_splitted/*.txt\"))\n",
    "lst_2j06RW0 = glob.glob(os.path.join(path_base, \"jitter06_rw0/all_splitted/*.txt\"))\n",
    "lst_2j07RW0 = glob.glob(os.path.join(path_base, \"jitter07_rw0/all_splitted/*.txt\"))\n",
    "lst_2j08RW0 = glob.glob(os.path.join(path_base, \"jitter08_rw0/all_splitted/*.txt\"))\n",
    "print(\"Found files[RealNoFloor]: %i\" %(len(lst_realNoFl)))\n",
    "print(\"Found files[lst_2j001RW0]: %i\" %(len(lst_2j001RW0)))\n",
    "print(\"Found files[lst_2j01RW0]: %i\" %(len(lst_2j01RW0)))\n",
    "print(\"Found files[lst_2j02RW0]: %i\" %(len(lst_2j02RW0)))\n",
    "print(\"Found files[lst_2j03RW0]: %i\" %(len(lst_2j03RW0)))\n",
    "print(\"Found files[lst_2j04RW0]: %i\" %(len(lst_2j04RW0)))\n",
    "print(\"Found files[lst_2j05RW0]: %i\" %(len(lst_2j05RW0)))\n",
    "print(\"Found files[lst_2j06RW0]: %i\" %(len(lst_2j06RW0)))\n",
    "print(\"Found files[lst_2j07RW0]: %i\" %(len(lst_2j07RW0)))\n",
    "print(\"Found files[lst_2j08RW0]: %i\" %(len(lst_2j08RW0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88544166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointCloudsDescriptor import PointCloudFEvaluator\n",
    "# Ray width \n",
    "pcD =  PointCloudFEvaluator()\n",
    "#\n",
    "dictList_real, biggest_real = pcD.pointCloud_generalDescription(lst_realNoFl, verbose=True)\n",
    "dictList_j001rw0, biggest_j001rw0 = pcD.pointCloud_generalDescription(lst_2j001RW0, verbose=True)\n",
    "dictList_j01rw0, biggest_j01rw0 = pcD.pointCloud_generalDescription(lst_2j01RW0, verbose=True)\n",
    "dictList_j02rw0, biggest_j02rw0 = pcD.pointCloud_generalDescription(lst_2j02RW0, verbose=True)\n",
    "dictList_j03rw0, biggest_j03rw0 = pcD.pointCloud_generalDescription(lst_2j03RW0, verbose=True)\n",
    "dictList_j04rw0, biggest_j04rw0 = pcD.pointCloud_generalDescription(lst_2j04RW0, verbose=True)\n",
    "dictList_j05rw0, biggest_j05rw0 = pcD.pointCloud_generalDescription(lst_2j05RW0, verbose=True)\n",
    "dictList_j06rw0, biggest_j06rw0 = pcD.pointCloud_generalDescription(lst_2j06RW0, verbose=True)\n",
    "dictList_j07rw0, biggest_j07rw0 = pcD.pointCloud_generalDescription(lst_2j07RW0, verbose=True)\n",
    "dictList_j08rw0, biggest_j08rw0 = pcD.pointCloud_generalDescription(lst_2j08RW0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density base on severeal spheres \n",
    "\n",
    "generalFileLst_jitter = [ lst_2j001RW0,  lst_2j01RW0, lst_2j02RW0, lst_2j03RW0, lst_2j04RW0, \n",
    "                          lst_2j05RW0, lst_2j06RW0, lst_2j07RW0, lst_2j08RW0]\n",
    "\n",
    "dic2SaveDJitter = {}\n",
    "\n",
    "for idx, aLst in enumerate(generalFileLst_jitter[0:1]):\n",
    "    for idx2, aFile in enumerate(aLst):\n",
    "        print(\"-> Loading[%i/%i] - Step[%i/%i]\" %(idx+1, len(generalFileLst_jitter), idx2+1, len(aLst)), end=\"\\r\" if idx2<len(aLst)-1 else \"\\n\")\n",
    "        a_pc = np.loadtxt(aFile)[:,0:3] \n",
    "        aDens = pcD.get_point_cloud_avg_density(a_pc)\n",
    "        if(idx not in dic2SaveDJitter.keys()):\n",
    "            dic2SaveDJitter[idx] = aDens\n",
    "        else:\n",
    "            dic2SaveDJitter[idx] = dic2SaveDJitter[idx] + aDens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2save = {}\n",
    "for akey in dic2keep2.keys():\n",
    "    bck = []\n",
    "    for valIn in dic2SaveDJitter[akey]:\n",
    "        bck.append( float(valIn) )\n",
    "    if (akey not in dic2save.keys()):\n",
    "        dic2save[akey] = bck\n",
    "print(len(dic2save.keys()))\n",
    "print(dic2save[0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "\n",
    "with open('raywidth_densities.json', \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "print(data.keys())\n",
    "sns.distplot(data['0'], hist = False, kde = True, bins=20)\n",
    "#sns.distplot(data['1'], hist = False, kde = True, bins=20)\n",
    "#sns.distplot(data['2'], hist = False, kde = True, bins=20)\n",
    "#sns.distplot(data['3'], hist = False, kde = True, bins=20)\n",
    "plt.legend([\"Real Scan\", \"J001RW0\", \"J001RW1\", \"J001RW2\"])\n",
    "plt.xlabel(\"Density\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jitter_densities.json', \"r\") as json_file:\n",
    "    data2 = json.load(json_file)\n",
    "print(data.keys())\n",
    "sns.distplot(data['0'], hist = False, kde = True, bins=20)\n",
    "sns.distplot(data2['0'], hist = False, kde = True, bins=20)\n",
    "sns.distplot(data2['3'], hist = False, kde = True, bins=20)\n",
    "sns.distplot(data2['7'], hist = False, kde = True, bins=20)\n",
    "\n",
    "plt.legend([\"Real Scan\", \"J01RW0\", \"J04RW0\", \"J08RW0\"])\n",
    "plt.xlabel(\"Density\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7284e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density base in one single volume \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "# Sort the list by volume \n",
    "sorted_real = pcD.sort_tree_by(dictList_real)\n",
    "sorted_j001rw0    = pcD.sort_tree_by(dictList_j001rw0)\n",
    "sorted_j01rw0     = pcD.sort_tree_by(dictList_j01rw0)\n",
    "sorted_j02rw0     = pcD.sort_tree_by(dictList_j02rw0)\n",
    "sorted_j03rw0     = pcD.sort_tree_by(dictList_j03rw0)\n",
    "sorted_j04rw0     = pcD.sort_tree_by(dictList_j04rw0)\n",
    "sorted_j05rw0     = pcD.sort_tree_by(dictList_j05rw0)\n",
    "sorted_j06rw0     = pcD.sort_tree_by(dictList_j06rw0)\n",
    "sorted_j07rw0     = pcD.sort_tree_by(dictList_j07rw0)\n",
    "sorted_j08rw0     = pcD.sort_tree_by(dictList_j08rw0)\n",
    "mergedList = [sorted_j001rw0, sorted_j01rw0, sorted_j02rw0, sorted_j03rw0, \n",
    "              sorted_j04rw0, sorted_j05rw0, sorted_j06rw0, sorted_j07rw0, sorted_j08rw0]\n",
    "# Dicts for the plots \n",
    "dicDensity = {}\n",
    "dictVolume = {}\n",
    "# Get all the volumes and densities and shape to make the plots \n",
    "for idx, aLst in enumerate(mergedList):\n",
    "    for aFile in aLst:\n",
    "        if(idx not in dicDensity.keys()):\n",
    "            dicDensity[idx] = [ aFile[\"pcShape\"][0]/aFile[\"volume\"] ]\n",
    "            dictVolume[idx] = [ aFile[\"volume\"] ]\n",
    "        else:\n",
    "            dicDensity[idx].append(aFile[\"pcShape\"][0]/aFile[\"volume\"])\n",
    "            dictVolume[idx].append(aFile[\"volume\"])    \n",
    "# Plot the volume list \n",
    "nTrees = range(len(sorted_j001rw0))\n",
    "#\n",
    "colors = [\"c-\", \"m-\", \"y-\", \"k-\", \"purple\", \"pink\", \"green\", \"lightcoral\", \"azure\"]\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "for i, acolor in zip(range(len(mergedList)), colors):\n",
    "    plt.plot(nTrees, dictVolume[i], acolor)\n",
    "    if(i==0):\n",
    "        plt.plot(nTrees, dictVolume[i], \"co\")\n",
    "plt.legend([\"J001RW0\", \"J01RW0\", \"J02RW0\", \"J03RW0\", \"J04RW0\", \"J05RW0\", \"J06RW0\", \"J07RW0\", \"J08RW0\"])\n",
    "plt.xlabel(\"Tree\")\n",
    "plt.ylabel(\"Volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrees = range(len(sorted_j001rw0))\n",
    "#\n",
    "colors = [\"c-\", \"m-\", \"y-\", \"k-\", \"purple\", \"pink\", \"green\", \"lightcoral\", \"azure\"]\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "for i, acolor in zip(range(len(mergedList)), colors):\n",
    "    plt.plot(nTrees, dicDensity[i], acolor)\n",
    "    if(i==0):\n",
    "        plt.plot(nTrees, dicDensity[i], \"co\")\n",
    "plt.legend([\"J001RW0\", \"J01RW0\", \"J02RW0\", \"J03RW0\", \"J04RW0\", \"J05RW0\", \"J06RW0\", \"J07RW0\", \"J08RW0\"])\n",
    "plt.xlabel(\"Tree\")\n",
    "plt.ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdedcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanDen = []\n",
    "meanVol = []\n",
    "colors = [\"c-\", \"m-\", \"y-\", \"k-\", \"purple\", \"pink\", \"green\", \"lightcoral\", \"azure\"]\n",
    "\n",
    "for dDens, dVol in zip(dicDensity.keys(), dictVolume.keys()):\n",
    "    meanDen.append( np.mean( np.array( dicDensity[dDens] ) ) )\n",
    "    meanVol.append( np.mean( np.array( dictVolume[dVol] ) ) )\n",
    "\n",
    "mReal = np.mean(np.array(d_real))\n",
    "mReal = [ mReal,mReal, mReal, mReal, mReal, mReal, mReal, mReal, mReal  ]\n",
    "plt.rcParams['figure.figsize'] = [9, 9]\n",
    "plt.plot(range(0, 9) ,meanDen, 'bo-')\n",
    "plt.plot(range(0, 9) ,mReal, 'r--')\n",
    "plt.legend([\"RealScan-AVG-Density\", \"Synthetic-AVG-Density\"])\n",
    "plt.xlabel(\"Jitter\")\n",
    "plt.ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32527cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "labels = [\"Real\", 'J001RW0', 'J001RW1', 'J001RW2']\n",
    "ax1.boxplot([d_real, d_s_j001rw0, d_s_j001rw1[0:-10], d_s_j001rw2[0:-10]], \n",
    "                     notch=True,  # notch shape\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True,  # fill with color\n",
    "                     labels=labels)\n",
    "plt.xlabel(\"Ray Width\")\n",
    "plt.ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9581bdef",
   "metadata": {},
   "source": [
    "### Comparison between the synthetic LiDAR scans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcfe61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jitter \n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(15, 9))\n",
    "labels = [\"Real\", 'J001RW0'] + [\"J0%sRW0\" %i for i in range(1, 9)]\n",
    "ax1.boxplot( [d_real]+[dicDensity[i] for i in range(len(mergedList))], \n",
    "                     notch=True,  # notch shape\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True,  # fill with color\n",
    "                     labels=labels)\n",
    "plt.xlabel(\"Experiment on Jitter\")\n",
    "plt.ylabel(\"Point density\")\n",
    "# ADD the real ones but you have to remove the soil!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(15, 9))\n",
    "labels = ['J001RW0'] + [\"J0%sRW0\" %i for i in range(1, 9)]\n",
    "print(len(labels))\n",
    "print(labels)\n",
    "ax1.boxplot([dictVolumeumeumelumeor i in range(len(mergedList))], \n",
    "                     notch=True,  # notch shape\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True,  # fill with color\n",
    "                     labels=labels)\n",
    "plt.xlabel(\"Experiment on Jitter\")\n",
    "plt.ylabel(\"Point density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42270c98",
   "metadata": {},
   "source": [
    "### Feature correlation in the real scan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ac92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pc_downsampling import Downsample\n",
    "# Concatenate the real trees and get their correlation matrix \n",
    "cPc = np.array([])\n",
    "ds  = Downsample() \n",
    "for idx, t in enumerate(lst_files_real):\n",
    "    print(\"-> Loading[%i/%i]\" %(idx+1, len(lst_files_real)), end=\"\\r\" if idx<len(lst_files_real) else \"\\n\")\n",
    "    a_pc_ = np.loadtxt(t)\n",
    "    #print(\"  -> Shape: %s\" %(str(a_pc_.shape)))\n",
    "    # Take only the points that are apples\n",
    "    #a_idx_ = np.where(a_pc_[:,6] == 1) # Apple's points\n",
    "    if(idx==0):\n",
    "        cPc = a_pc_#[a_idx_]\n",
    "    else:\n",
    "        cPc = np.append(cPc, a_pc_, axis=0)\n",
    "# Downsample randomly \n",
    "#rs_apple_pts = ds.decimation(cPc, npoints=3000)\n",
    "corrM = np.corrcoef(cPc.transpose())# The feature are allong the rows!\n",
    "\n",
    "x_axis_labels = [\"X\", \"Y\", \"Z\",\"Reflectance\", \"Deviation\", \"Amplitude\", \"Annotation\"] # labels for x-axis\n",
    "y_axis_labels = [\"X\", \"Y\", \"Z\",\"Reflectance\", \"Deviation\", \"Amplitude\", \"Annotation\"] # labels for y-axis\n",
    "\n",
    "# create seabvorn heatmap with required labels\n",
    "sns.heatmap(corrM, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094340f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pc_downsampling import Downsample\n",
    "# Real data FPFH\n",
    "path2fpfh = \"/media/juan/jprb/PhD_2020_2023/Data/annotated_data_realTrees/Featured_FPFH/\"\n",
    "lst_real_fpfh = glob.glob( os.path.join(path2fpfh, \"*.txt\") )\n",
    "# Concatenate the real trees and get their correlation matrix \n",
    "cPc = np.array([])\n",
    "ds  = Downsample() \n",
    "for idx, t in enumerate(lst_real_fpfh):\n",
    "    print(\"-> Loading[%i/%i]\" %(idx+1, len(lst_real_fpfh)), end=\"\\r\" if idx<len(lst_real_fpfh) else \"\\n\")\n",
    "    a_pc_ = np.loadtxt(t)\n",
    "    #print(\"  -> Shape: %s\" %(str(a_pc_.shape)))\n",
    "    # Take only the points that are apples\n",
    "    #a_idx_ = np.where(a_pc_[:,6] == 1) # Apple's points\n",
    "    if(idx==0):\n",
    "        cPc = a_pc_#[a_idx_]\n",
    "    else:\n",
    "        cPc = np.append(cPc, a_pc_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93199869",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrM = np.corrcoef(cPc.transpose())# The feature are allong the rows!\n",
    "#cPc = []\n",
    "x_axis_labels = [\"X\", \"Y\", \"Z\",\"Reflectance\", \"Deviation\", \"Amplitude\", \"Annotation\" ] + [i for i in range(1,33)] # labels for y-axis\n",
    "y_axis_labels = [\"X\", \"Y\", \"Z\",\"Reflectance\", \"Deviation\", \"Amplitude\", \"Annotation\" ] + [i for i in range(1,33)] # labels for y-axis\n",
    "\n",
    "# create seabvorn heatmap with required labels\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "sns.heatmap(corrM, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix Synthetic data \n",
    "import os \n",
    "import glob \n",
    "import numpy as np \n",
    "from pointCloudsDescriptor import PointCloudFEvaluator\n",
    "#\n",
    "pcD = PointCloudFEvaluator()\n",
    "#\n",
    "path_base = \"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/\"\n",
    "lst_jitter01_rw0 = glob.glob(os.path.join(path_base, \"jitter01_rw0/all_fpfh/*.txt\"))\n",
    "# \n",
    "cPc = np.array([])\n",
    "for idx, t in enumerate(lst_jitter01_rw0):\n",
    "    print(\"-> Loading[%i/%i]\" %(idx+1, len(lst_jitter01_rw0)), end=\"\\r\" if idx<len(lst_jitter01_rw0) else \"\\n\")\n",
    "    a_pc_ = np.loadtxt(t)\n",
    "    #print(\"  -> Shape: %s\" %(str(a_pc_.shape)))\n",
    "    # Take only the points that are apples\n",
    "    #a_idx_ = np.where(a_pc_[:,6] == 1) # Apple's points\n",
    "    if(idx==0):\n",
    "        cPc = a_pc_#[a_idx_]\n",
    "    else:\n",
    "        cPc = np.append(cPc, a_pc_, axis=0)\n",
    "corrM = np.corrcoef(cPc.transpose())# The feature are allong the rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "x_axis_labels = [\"X\", \"Y\", \"Z\", \"Annotation\" ] + [i for i in range(1,33)] # labels for y-axis\n",
    "y_axis_labels = [\"X\", \"Y\", \"Z\", \"Annotation\" ] + [i for i in range(1,33)] # labels for y-axis\n",
    "\n",
    "# create seabvorn heatmap with required labels\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "sns.heatmap(corrM, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ae712",
   "metadata": {},
   "source": [
    "### Apple Standard Deviation and Averange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4162c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob \n",
    "import numpy as np\n",
    "# Real data \n",
    "path_real = \"/media/juan/jprb/PhD_2020_2023/Data/annotated_data_realTrees/\"\n",
    "# Synthetic data \n",
    "base_path_syn = \"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/\"\n",
    "# List \n",
    "lst_real_tre = glob.glob(os.path.join(path_real, \"*.txt\"))\n",
    "# Ray width \n",
    "lst_j001_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter001_rw0/all_splited/*.txt\"))\n",
    "lst_j001_rw1 = glob.glob(os.path.join(base_path_syn, \"jitter001_rw1/all_splitted/*.txt\"))\n",
    "lst_j001_rw2 = glob.glob(os.path.join(base_path_syn, \"jitter001_rw2/all_splitted/*.txt\"))\n",
    "# Jitter\n",
    "lst_j01_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter01_rw0/all_splitted/*.txt\"))\n",
    "lst_j02_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter02_rw0/all_splitted/*.txt\"))\n",
    "lst_j03_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter03_rw0/all_splitted/*.txt\"))\n",
    "lst_j04_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter04_rw0/all_splitted/*.txt\"))\n",
    "lst_j05_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter05_rw0/all_splitted/*.txt\"))\n",
    "lst_j06_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter06_rw0/all_splitted/*.txt\"))\n",
    "lst_j07_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter07_rw0/all_splitted/*.txt\"))\n",
    "lst_j08_rw0 = glob.glob(os.path.join(base_path_syn, \"jitter08_rw0/all_splitted/*.txt\"))\n",
    "# \n",
    "print(\"Found Elements: %i\" %(len(lst_j001_rw0)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j001_rw1)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j001_rw2)))\n",
    "\n",
    "print(\"Found Elements: %i\" %(len(lst_j01_rw0)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j02_rw0)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j03_rw0)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j04_rw0)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j05_rw0)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j06_rw0)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j07_rw0)))\n",
    "print(\"Found Elements: %i\" %(len(lst_j08_rw0)))\n",
    "#\n",
    "mLstSyn = [lst_real_tre, lst_j001_rw0, lst_j001_rw1, lst_j001_rw2, lst_j01_rw0, lst_j02_rw0, lst_j03_rw0, \n",
    "           lst_j04_rw0, lst_j05_rw0, lst_j06_rw0, lst_j07_rw0, lst_j08_rw0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b38005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of radiometric features \n",
    "# Save variables \n",
    "sDic = {\"Reflectance_apple\": np.array([]), \"Reflectance_NoNapple\": np.array([]), \"Deviation_apple\": np.array([]), \"Deviation_NoNapple\": np.array([]), \"Amplitude_apple\": np.array([]), \"Amplitude_NoNapple\": np.array([])}\n",
    "for idx, aNamePc in enumerate(lst_real_tre):\n",
    "    print(\"Loading[%i/%i]: \" %(idx+1, len(lst_real_tre)), end=\"\\r\" if idx<len(lst_real_tre) else \"\\n\" )\n",
    "    a_pc = np.loadtxt(aNamePc)\n",
    "    appleIdx = np.where(a_pc[:,6] == 1)\n",
    "    NoNappleIdx = np.where(a_pc[:,6] != 1)\n",
    "    #print(\"Loading[%i/%i]: \\n -> Shape: %s, apple: %i, NonApple: %i\" %(idx+1, len(lst_real_tre), str(a_pc.shape), len(appleIdx[0]),len(NoNappleIdx[0])  ), end=\"\\r\" if idx<len(lst_real_tre) else \"\\n\" )\n",
    "    if(idx == 0):\n",
    "        sDic[\"Reflectance_apple\"]    = a_pc[appleIdx, 3].reshape(-1,1)  \n",
    "        sDic[\"Reflectance_NoNapple\"] = a_pc[NoNappleIdx, 3].reshape(-1,1)\n",
    "\n",
    "        sDic[\"Deviation_apple\"]    = a_pc[appleIdx, 4].reshape(-1,1)\n",
    "        sDic[\"Deviation_NoNapple\"] = a_pc[NoNappleIdx, 4].reshape(-1,1)\n",
    "\n",
    "        sDic[\"Amplitude_apple\"]    = a_pc[appleIdx, 5].reshape(-1,1)\n",
    "        sDic[\"Amplitude_NoNapple\"] = a_pc[NoNappleIdx, 5].reshape(-1,1)\n",
    "    else:\n",
    "        sDic[\"Reflectance_apple\"]    = np.concatenate( [sDic[\"Reflectance_apple\"],   a_pc[appleIdx, 3].reshape(-1,1)], axis=0 )  \n",
    "        sDic[\"Reflectance_NoNapple\"] = np.concatenate( [sDic[\"Reflectance_NoNapple\"],   a_pc[NoNappleIdx, 3].reshape(-1,1)], axis=0 )\n",
    "\n",
    "        sDic[\"Deviation_apple\"]    = np.concatenate( [sDic[\"Deviation_apple\"],   a_pc[appleIdx, 4].reshape(-1,1)], axis=0 )\n",
    "        sDic[\"Deviation_NoNapple\"] = np.concatenate( [sDic[\"Deviation_NoNapple\"],   a_pc[NoNappleIdx, 4].reshape(-1,1)], axis=0 )\n",
    "\n",
    "        sDic[\"Amplitude_apple\"]    = np.concatenate( [sDic[\"Amplitude_apple\"],   a_pc[appleIdx, 5].reshape(-1,1)], axis=0 )\n",
    "        sDic[\"Amplitude_NoNapple\"] = np.concatenate( [sDic[\"Amplitude_NoNapple\"],   a_pc[NoNappleIdx, 5].reshape(-1,1)], axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a20b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import pandas as pd \n",
    "%matplotlib inline \n",
    "\n",
    "mean_apple_reflectance = np.mean(sDic[\"Reflectance_apple\"])\n",
    "print(\"Mean Reflectance [Apple]: %.4f\" %(mean_apple_reflectance) )\n",
    "std_apple_reflectance = np.std(sDic[\"Reflectance_apple\"])\n",
    "print(\"STD Reflectance [NoN Apple]: %.4f\\n\" %(std_apple_reflectance) )\n",
    "mean_NoNapple_reflectance = np.mean(sDic[\"Reflectance_NoNapple\"])\n",
    "print(\"Mean Reflectance [Apple]: %.4f\" %(mean_NoNapple_reflectance) )\n",
    "Std_NoNapple_reflectance = np.std(sDic[\"Reflectance_NoNapple\"])\n",
    "print(\"STD Reflectance [Non Apple]: %.4f\" %(mean_NoNapple_reflectance) )\n",
    "\n",
    "\n",
    "#sns.distplot(sDic[\"Reflectance_apple\"], hist = True, kde = True, bins=20)\n",
    "#sns.distplot(sDic[\"Reflectance_NoNapple\"], hist = True, kde = True, bins=20)\n",
    "\n",
    "#sns.kdeplot(data = sDic[\"Reflectance_NoNapple\"])\n",
    "#fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 15))\n",
    "\n",
    "#ax = plt.subplot(2, 1, 1)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.hist(sDic[\"Reflectance_apple\"], density=True, bins=20, alpha=0.5)\n",
    "plt.hist(sDic[\"Reflectance_NoNapple\"], density=True, bins=20, alpha=0.5)\n",
    "plt.ylabel(\"Normalize Frequency\")\n",
    "plt.xlabel(\"Reflectance\")\n",
    "plt.legend([\"Apple\", \"Non Apple\"])\n",
    "plt.xlim([10, 40])\n",
    "plt.ylim([0, 0.40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd18ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_apple_deviation = np.mean(sDic[\"Deviation_apple\"])\n",
    "print(\"Mean Deviation [Apple]: %.4f\" %(mean_apple_deviation) )\n",
    "std_apple_deviation = np.std(sDic[\"Deviation_apple\"])\n",
    "print(\"STD Deviation [NoN Apple]: %.4f\\n\" %(std_apple_deviation) )\n",
    "mean_NoNapple_deviation = np.mean(sDic[\"Deviation_NoNapple\"])\n",
    "print(\"Mean Deviation [Apple]: %.4f\" %(mean_NoNapple_deviation) )\n",
    "Std_NoNapple_deviation = np.std(sDic[\"Deviation_NoNapple\"])\n",
    "print(\"STD Deviation [Non Apple]: %.4f\" %(mean_NoNapple_deviation) )\n",
    "\n",
    "#sns.distplot(sDic[\"Deviation_apple\"], hist = False, kde = True)\n",
    "#sns.distplot(sDic[\"Deviation_NoNapple\"], hist = False, kde = True)\n",
    "\n",
    "\n",
    "#sns.kdeplot(data = sDic[\"Reflectance_NoNapple\"])\n",
    "#fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 15))\n",
    "\n",
    "#ax = plt.subplot(2, 1, 1)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.hist(sDic[\"Deviation_apple\"], density=True, bins=20, alpha=0.5)\n",
    "plt.hist(sDic[\"Deviation_NoNapple\"], density=True, bins=20, alpha=0.5)\n",
    "plt.ylabel(\"Normalize Frequency\")\n",
    "plt.xlabel(\"Deviation\")\n",
    "plt.legend([\"Apple\", \"Non Apple\"])\n",
    "plt.ylim([0, 0.40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.hist(sDic[\"Amplitude_apple\"], density=True, bins=20, alpha=0.5)\n",
    "plt.hist(sDic[\"Amplitude_NoNapple\"], density=True, bins=20, alpha=0.5)\n",
    "plt.ylabel(\"Normalize Frequency\")\n",
    "plt.xlabel(\"Amplitude\")\n",
    "plt.legend([\"Apple\", \"Non Apple\"])\n",
    "plt.xlim([-25, 5])\n",
    "plt.ylim([0, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicGeneral = {}\n",
    "# Load the point clouds, get the apple and non apple point and estimate their STD and AVG \n",
    "for idx, aLst in enumerate(mLstSyn):\n",
    "    # Annotation column on the real and synthetic data \n",
    "    if(idx==0):\n",
    "        annCol = 6\n",
    "    else: \n",
    "        annCol = 3\n",
    "    for afile in aLst:\n",
    "        a_pc = np.loadtxt(afile)\n",
    "        # Get the Idx of the apples and the non Apples points\n",
    "        idx_apples = np.where(a_pc[:, annCol]==1) # Apples\n",
    "        idx_NoNapples = np.where(a_pc[:, annCol]!=1) # Non Apples \n",
    "        print(\"AnnCol: %i, Elements: %s\" %( annCol, str(np.unique(a_pc[:, annCol])) ) )\n",
    "        print(\"idx: %i, ApplesPts: %i -- %s , NonApplesPts: %i -- %s\" %( idx, len(idx_apples[0]), \n",
    "        str( np.unique(a_pc[idx_apples,annCol] ) ), len(idx_NoNapples[0]),\n",
    "            str( np.unique(a_pc[idx_NoNapples,annCol] ) )))\n",
    "        # \n",
    "        \n",
    "        if(idx not in dicGeneral.keys()):\n",
    "            if(idx==0):\n",
    "                dicGeneral[idx] =  {\"appleSTD_xyz\": [np.std( a_pc[idx_apples, 0:3])], \n",
    "                                   \"appleSTD_reflectance\": [np.std( a_pc[idx_apples, 3])],\n",
    "                                   \"appleSTD_deviation\": [np.std( a_pc[idx_apples, 4])], \n",
    "                                   \"appleSTD_Amplitude\": [np.std( a_pc[idx_apples, 5])], \n",
    "                                   \"appleSTD_AllRadio\": [np.std( a_pc[idx_apples, 3:6])], \n",
    "                                   \"appleAVG_xyz\": [np.mean( a_pc[idx_apples, 0:3])], \n",
    "                                   \"appleAVG_reflectance\": [np.mean( a_pc[idx_apples, 3])],\n",
    "                                   \"appleAVG_deviation\": [np.mean( a_pc[idx_apples, 4])], \n",
    "                                   \"appleAVG_Amplitude\": [np.mean( a_pc[idx_apples, 5])], \n",
    "                                   \"appleAVG_AllRadio\": [np.mean( a_pc[idx_apples, 3:6])], \n",
    "                                   \"NoNappleSTD_xyz\": [np.std( a_pc[idx_NoNapples, 0:3])], \n",
    "                                   \"NoNappleSTD_reflectance\": [np.std( a_pc[idx_NoNapples, 3])],\n",
    "                                   \"NoNappleSTD_deviation\": [np.std( a_pc[idx_NoNapples, 4])], \n",
    "                                   \"NoNappleSTD_Amplitude\": [np.std( a_pc[idx_NoNapples, 5])], \n",
    "                                   \"NoNappleSTD_AllRadio\": [np.std( a_pc[idx_NoNapples, 3:6])], \n",
    "                                   \"NoNappleAVG_xyz\": [np.mean( a_pc[idx_NoNapples, 0:3])], \n",
    "                                   \"NoNappleAVG_reflectance\": [np.mean( a_pc[idx_NoNapples, 3])],\n",
    "                                   \"NoNappleAVG_deviation\": [np.mean( a_pc[idx_NoNapples, 4])], \n",
    "                                   \"NoNappleAVG_Amplitude\": [np.mean( a_pc[idx_NoNapples, 5])], \n",
    "                                   \"NoNappleAVG_AllRadio\": [np.mean( a_pc[idx_NoNapples, 3:6])]}\n",
    "            else:\n",
    "                dicGeneral[idx] = {\"appleSTD_xyz\": [np.std( a_pc[idx_apples, 0:3])], \n",
    "                                   \"appleAVG_xyz\": [np.mean( a_pc[idx_apples, 0:3])], \n",
    "                                   \"NoNappleSTD_xyz\": [np.std( a_pc[idx_NoNapples, 0:3])], \n",
    "                                   \"NoNappleAVG_xyz\": [np.mean( a_pc[idx_NoNapples, 0:3])]}\n",
    "        else:\n",
    "            if(idx==0):\n",
    "                # Apple\n",
    "                dicGeneral[idx][\"appleSTD_xyz\"].append(np.std( a_pc[idx_apples, 0:3] ) )\n",
    "                dicGeneral[idx][\"appleSTD_reflectance\"].append(np.std( a_pc[idx_apples, 3]))\n",
    "                dicGeneral[idx][\"appleSTD_deviation\"].append(np.std( a_pc[idx_apples, 4]))\n",
    "                dicGeneral[idx][\"appleSTD_Amplitude\"].append(np.std( a_pc[idx_apples, 5]))\n",
    "                dicGeneral[idx][\"appleSTD_AllRadio\"].append(np.std( a_pc[idx_apples, 3:6]))\n",
    "                dicGeneral[idx][\"appleAVG_xyz\"].append(np.mean( a_pc[idx_apples, 0:3] ) )\n",
    "                dicGeneral[idx][\"appleAVG_reflectance\"].append(np.mean( a_pc[idx_apples, 3]))\n",
    "                dicGeneral[idx][\"appleAVG_deviation\"].append(np.mean( a_pc[idx_apples, 4]))\n",
    "                dicGeneral[idx][\"appleAVG_Amplitude\"].append(np.mean( a_pc[idx_apples, 5]))\n",
    "                dicGeneral[idx][\"appleAVG_AllRadio\"].append(np.mean( a_pc[idx_apples, 3:6]))\n",
    "                # Non Apple \n",
    "                dicGeneral[idx][\"NoNappleSTD_xyz\"].append(np.std( a_pc[idx_NoNapples, 0:3] ) )\n",
    "                dicGeneral[idx][\"NoNappleSTD_reflectance\"].append(np.std( a_pc[idx_NoNapples, 3]))\n",
    "                dicGeneral[idx][\"NoNappleSTD_deviation\"].append(np.std( a_pc[idx_NoNapples, 4]))\n",
    "                dicGeneral[idx][\"NoNappleSTD_Amplitude\"].append(np.std( a_pc[idx_NoNapples, 5]))\n",
    "                dicGeneral[idx][\"NoNappleSTD_AllRadio\"].append(np.std( a_pc[idx_NoNapples, 3:6]))\n",
    "                dicGeneral[idx][\"NoNappleAVG_xyz\"].append(np.mean( a_pc[idx_NoNapples, 0:3] ) )\n",
    "                dicGeneral[idx][\"NoNappleAVG_reflectance\"].append(np.mean( a_pc[idx_NoNapples, 3]))\n",
    "                dicGeneral[idx][\"NoNappleAVG_deviation\"].append(np.mean( a_pc[idx_NoNapples, 4]))\n",
    "                dicGeneral[idx][\"NoNappleAVG_Amplitude\"].append(np.mean( a_pc[idx_NoNapples, 5]))\n",
    "                dicGeneral[idx][\"NoNappleAVG_AllRadio\"].append(np.mean( a_pc[idx_NoNapples, 3:6]))\n",
    "            else:\n",
    "                dicGeneral[idx][\"appleSTD_xyz\"].append( np.std( a_pc[idx_apples, 0:3]) )\n",
    "                dicGeneral[idx][\"appleAVG_xyz\"].append( np.mean( a_pc[idx_apples, 0:3]) ) \n",
    "                dicGeneral[idx][\"NoNappleSTD_xyz\"].append( np.std( a_pc[idx_NoNapples, 0:3]) )\n",
    "                dicGeneral[idx][\"NoNappleAVG_xyz\"].append( np.mean( a_pc[idx_NoNapples, 0:3]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np \n",
    "# Values of the real scan \n",
    "#print( json.dumps(dicGeneral[0],  sort_keys=True, indent=4) )\n",
    "# Mean of all the values \n",
    "print(\"AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[0][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[0][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[0][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[0][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"AVG of Apples (Reflectance): %.4f\" %(np.mean(np.array( dicGeneral[0][\"appleAVG_reflectance\"] ) ) ))\n",
    "print(\"AVG of NoNApples (Reflectance): %.4f\" %(np.mean(np.array( dicGeneral[0][\"NoNappleAVG_reflectance\"] ) ) ))\n",
    "print(\"AVG STD of Apples (Reflectance): %.4f\" %(np.mean(np.array( dicGeneral[0][\"appleSTD_reflectance\"] ) ) ))\n",
    "print(\"AVG STD of NoNApples (Reflectance): %.4f\\n\" %(np.mean(np.array( dicGeneral[0][\"NoNappleSTD_reflectance\"] ) ) ))\n",
    "\n",
    "print(\"AVG of Apples (Deviation): %.4f\" %( np.mean(np.array( dicGeneral[0][\"appleAVG_deviation\"] ) ) ))\n",
    "print(\"AVG of NoNApples (Deviation): %.4f\" %( np.mean(np.array( dicGeneral[0][\"NoNappleAVG_deviation\"] ) ) ))\n",
    "print(\"AVG STD of Apples (Deviation): %.4f\" %( np.mean(np.array( dicGeneral[0][\"appleSTD_deviation\"] ) ) ))\n",
    "print(\"AVG STD of NoNApples (Deviation): %.4f\\n\" %( np.mean(np.array( dicGeneral[0][\"NoNappleSTD_deviation\"] ) ) ))\n",
    "\n",
    "print(\"AVG of Apples (Amplitude): %.4f\" %( np.mean(np.array( dicGeneral[0][\"appleAVG_Amplitude\"] ) ) ))\n",
    "print(\"AVG of NoNApples (Amplitude): %.4f\" %( np.mean(np.array( dicGeneral[0][\"NoNappleAVG_Amplitude\"] ) ) ))\n",
    "print(\"AVG STD of Apples (Amplitude): %.4f\" %( np.mean(np.array( dicGeneral[0][\"appleSTD_Amplitude\"] ) ) ))\n",
    "print(\"AVG STD of NoNApples (Amplitude): %.4f\\n\" %( np.mean(np.array( dicGeneral[0][\"NoNappleSTD_Amplitude\"] ) ) ))\n",
    "\n",
    "print(\"AVG of Apples (AllRadiometric): %.4f\" %( np.mean(np.array( dicGeneral[0][\"appleAVG_AllRadio\"] ) ) ))\n",
    "print(\"AVG of NoNApples (AllRadiometric): %.4f\" %( np.mean(np.array( dicGeneral[0][\"NoNappleAVG_AllRadio\"] ) ) ))\n",
    "print(\"AVG STD of Apples (AllRadiometric): %.4f\" %( np.mean(np.array( dicGeneral[0][\"appleSTD_AllRadio\"] ) ) ))\n",
    "print(\"AVG STD of NoNApples (AllRadiometric): %.4f\\n\" %( np.mean(np.array( dicGeneral[0][\"NoNappleSTD_AllRadio\"] ) ) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d0e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sintetica\n",
    "# Ray width \n",
    "print(\"J001RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[1][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J001RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[1][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J001RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[1][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J001RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[1][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J001RW1-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[2][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J001RW1-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[2][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J001RW1-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[2][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J001RW1-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[2][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J001RW2-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[3][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J001RW2-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[3][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J001RW2-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[3][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J001RW2-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[3][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "# Jitter \n",
    "print(\"J01RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[4][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J01RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[4][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J01RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[4][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J01RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[4][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J02RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[5][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J02RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[5][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J02RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[5][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J02RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[5][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J03RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[6][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J03RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[6][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J03RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[6][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J03RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[6][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J04RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[7][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J04RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[7][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J04RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[7][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J04RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[7][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J05RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[8][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J05RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[8][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J05RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[8][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J05RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[8][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J06RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[9][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J06RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[9][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J06RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[9][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J06RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[9][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J07RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[10][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J07RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[10][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J07RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[10][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J07RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[10][\"NoNappleSTD_xyz\"] ) ) ))\n",
    "\n",
    "print(\"J08RW0-AVG of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[11][\"appleAVG_xyz\"] ) ) ))\n",
    "print(\"J08RW0-AVG of NoNApples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[11][\"NoNappleAVG_xyz\"] ) ) ))\n",
    "print(\"J08RW0-AVG STD of Apples (XYZ): %.4f\" %( np.mean(np.array( dicGeneral[11][\"appleSTD_xyz\"] ) ) ))\n",
    "print(\"J08RW0-AVG STD of NoNApples (XYZ): %.4f\\n\" %( np.mean(np.array( dicGeneral[11][\"NoNappleSTD_xyz\"] ) ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "plt.rcParams['figure.figsize'] = [25, 20]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.25)\n",
    "\n",
    "# Plots Real scan Apple Non Apple \n",
    "for idx, i in enumerate(dicGeneral[0].keys(), start=1):\n",
    "    ax = fig.add_subplot(5, 4, idx)\n",
    "    ax.boxplot(dicGeneral[0][i], \n",
    "                     notch=True,  # notch shape\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True)  # fill with color)\n",
    "    plt.xlabel(i,labelpad=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and std number of points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a34ba5",
   "metadata": {},
   "source": [
    "## Evaluation of the Random Forest and RandLA-NET trained models over synthetic and real scans -- Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50caf0",
   "metadata": {},
   "source": [
    "## Synthetic Scans - Random Fores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a250b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline \n",
    "\n",
    "def getFileName(path2file):\n",
    "    lstFolders = os.path.split(path2file)\n",
    "    LstfStr = lstFolders[-1].split('.')\n",
    "    return LstfStr[0]\n",
    "\n",
    "def get_confMatrix_experiment(lstGT, lstPT, annCol, P=0.7):\n",
    "    lst_exp_gt = []\n",
    "    lst_exp_pr = []\n",
    "    for idx, baseFile in enumerate(lstGT, start=1):\n",
    "        print(\"Loading[%i/%i]\" %( idx, len(lstGT) ), end= \"\\r\" if idx<len(lstGT) else \"\\n\" )\n",
    "        base_name2compare = getFileName(baseFile)\n",
    "        bs_pc = np.loadtxt(baseFile)[:,annCol].astype(np.uint8)\n",
    "        for predictedFile in lstPT:\n",
    "            predicted_name2compare = getFileName(predictedFile)\n",
    "            if(predicted_name2compare==base_name2compare):\n",
    "                pt_pc = np.loadtxt(predictedFile)[:,annCol]\n",
    "                pt_pc = np.where(pt_pc>P, 1, 0)\n",
    "                lst_exp_gt = lst_exp_gt + list( bs_pc )\n",
    "                lst_exp_pr = lst_exp_pr + list( pt_pc ) \n",
    "                break \n",
    "    return confusion_matrix(lst_exp_gt, lst_exp_pr, normalize=\"true\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# J01RW0\n",
    "ground_truth_j01_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter01_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test/\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j01_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter01_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted/\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J01RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j01_rw0), len(predicted_j01_rw0) ) )\n",
    "confM_j01rw0  = get_confMatrix_experiment(ground_truth_j01_rw0, predicted_j01_rw0, 3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j01rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J01RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J02RW0\n",
    "ground_truth_j02_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter02_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test/\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j02_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter02_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted/\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J02RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j02_rw0), len(predicted_j02_rw0) ) )\n",
    "confM_j02rw0  = get_confMatrix_experiment(ground_truth_j02_rw0, predicted_j02_rw0, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j02rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J02RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe62793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J03RW0\n",
    "ground_truth_j03_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter03_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test/\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j03_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter03_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted/\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J03RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j03_rw0), len(predicted_j03_rw0) ) )\n",
    "confM_j03rw0  = get_confMatrix_experiment(ground_truth_j03_rw0, predicted_j03_rw0, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j03rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J03RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J04RW0\n",
    "ground_truth_j04_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter04_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test/\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j04_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter04_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted/\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J03RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j04_rw0), len(predicted_j04_rw0) ) )\n",
    "confM_j04rw0  = get_confMatrix_experiment(ground_truth_j04_rw0, predicted_j04_rw0, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j04rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J04RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ba705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J05RW0\n",
    "ground_truth_j05_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter05_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test/\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j05_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter05_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted/\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J05RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j05_rw0), len(predicted_j05_rw0) ) )\n",
    "confM_j05rw0  = get_confMatrix_experiment(ground_truth_j05_rw0, predicted_j05_rw0, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j05rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J05RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J06RW0\n",
    "ground_truth_j06_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter06_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test/\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j06_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter06_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted/\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J06RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j06_rw0), len(predicted_j06_rw0) ) )\n",
    "confM_j06rw0  = get_confMatrix_experiment(ground_truth_j06_rw0, predicted_j06_rw0, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j06rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J06RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J07RW0\n",
    "ground_truth_j07_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter07_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j07_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter07_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J07RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j07_rw0), len(predicted_j07_rw0) ) )\n",
    "confM_j07rw0  = get_confMatrix_experiment(ground_truth_j07_rw0, predicted_j07_rw0, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j07rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J07RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J08RW0\n",
    "ground_truth_j08_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter08_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j08_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter08_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted/\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J08RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j08_rw0), len(predicted_j08_rw0) ) )\n",
    "confM_j08rw0  = get_confMatrix_experiment(ground_truth_j08_rw0, predicted_j08_rw0, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j08rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J08RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J08RW0\n",
    "ground_truth_j001_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter001_rw0/special_split_featured_apples/susbset_at_0.8/train_test/test\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j001_rw0 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter001_rw0/special_split_featured_apples/susbset_at_0.8/train_test/predicted\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J001RW0 --- GT: %i | PT; %i\" %( len(ground_truth_j001_rw0), len(predicted_j001_rw0) ) )\n",
    "confM_j001rw0  = get_confMatrix_experiment(ground_truth_j001_rw0, predicted_j001_rw0, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j001rw0, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J001RW0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89984d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_j001_rw1 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter001_rw1/special_split_featured_apples/susbset_at_0.8/train_test/test\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j001_rw1 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter001_rw1/special_split_featured_apples/susbset_at_0.8/train_test/predicted\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J001RW2 --- GT: %i | PT; %i\" %( len(ground_truth_j001_rw1), len(predicted_j001_rw1) ) )\n",
    "confM_j001rw1 = get_confMatrix_experiment(ground_truth_j001_rw1, predicted_j001_rw1, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j001rw1, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J001RW1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_j001_rw2 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter001_rw2/special_split_featured_apples/susbset_at_0.8/train_test/test/\", \n",
    "                                              \"*.txt\") )\n",
    "predicted_j001_rw2 = glob.glob(os.path.join(\"/media/juan/jprb/PhD_2020_2023/Data/synthetic_experiments_jitter_raywidth_juan/orderedSynthetic/synthetic_exp/jitter001_rw2/special_split_featured_apples/susbset_at_0.8/train_test/predicted/\", \n",
    "                                              \"*.txt\") )\n",
    "print(\"J001RW2 --- GT: %i | PT; %i\" %( len(ground_truth_j001_rw2), len(predicted_j001_rw2) ) )\n",
    "confM_j001rw2  = get_confMatrix_experiment(ground_truth_j001_rw2, predicted_j001_rw2, 3)\n",
    "\n",
    "x_axis_labels = [\"Non Apple\", \"Apple\"] # labels for x-axis\n",
    "y_axis_labels = [\"Non Apple\", \"Apple\"] # labels for y-axis\n",
    "\n",
    "sns.heatmap(confM_j001rw2, linewidths=.5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot = True, cmap=\"Blues_r\")\n",
    "plt.title(\"J001RW2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37d3e2",
   "metadata": {},
   "source": [
    "## RandLA-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718862b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e11a68f4",
   "metadata": {},
   "source": [
    "## Clustering and Apple Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- PC and BGEOM ERR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
