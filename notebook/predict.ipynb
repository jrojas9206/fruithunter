{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "green-tissue",
   "metadata": {},
   "source": [
    "# Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_path_and_fileName(strPathName):\n",
    "    \"\"\"\n",
    "    Split the path and the name of the file of the given string \n",
    "    :INPUT:\n",
    "        strPathName: str with the path and name of a file. ex: /data/pointcloud.txt\n",
    "    :OUTPUT:\n",
    "        list, [\"/data/\", \"pointcloud.txt\"]\n",
    "    \"\"\"\n",
    "    for idx in range(len(strPathName)-1, 0, -1):\n",
    "        if(strPathName[idx]=='/'):\n",
    "            return strPathName[0:idx], strPathName[idx+1:]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from randlanet.utils.data_prepare_apple_tree import * \n",
    "def dataSet(path2files, path2output, model, verbose=False, protocol=\"field\"):\n",
    "    \"\"\"\n",
    "    :INPUT:\n",
    "        path2files : str of the path to the folder of input files\n",
    "        path2output: str of the path to the output folder \n",
    "        model      : str, \"rdf\" or \"rdnet\"\n",
    "        verbose    : If true print few message of the code steps \n",
    "        protocol   : Type of protocol to handle ; synthetic/field/field_only_xyz\n",
    "    :OUTPUT:\n",
    "        Write the splitted dataset  on the folder\n",
    "    \"\"\"\n",
    "    # NOTE: This segment will be only executed from the notebook \n",
    "    lstOfFiles = glob.glob(os.path.join(path2files,\"*.txt\"))\n",
    "    if(verbose):\n",
    "        print(\"Found files: %i \" %(len(lstOfFiles)))\n",
    "    # Split the files\n",
    "    #X_train, X_test, _,_ = train_test_split(lstOfFiles, range(len(lstOfFiles)), test_size=0.20, random_state=42)\n",
    "    if(verbose):\n",
    "        print(\" -> Train set: %i\" %len(X_train))\n",
    "        print(\" -> Test set : %i\" %len(X_test))\n",
    "    # Create the directory to keep the test and train sets \n",
    "    path2initialSplit = path2output #os.path.join(data2annotatedApples, \"dataToRDF\")\n",
    "    if(not os.path.isdir(path2initialSplit)):\n",
    "        os.mkdir(path2initialSplit)\n",
    "    for folderName, fileList in zip( [\"test\" if model == \"rdf\" else \"test\"], [lstOfFiles] ):\n",
    "        path2saveData = os.path.join(path2initialSplit)\n",
    "        for file2feature in fileList:\n",
    "            output2wrt = os.path.join(path2saveData, folderName)\n",
    "            if(not os.path.isdir(output2wrt)):\n",
    "                os.mkdir(output2wrt)\n",
    "                print(\"Folder was created: %s\" %output2wrt)\n",
    "            print(\"-> Loading: %s\" %split_path_and_fileName(file2feature)[1])\n",
    "            file2wrt = os.path.join(output2wrt, split_path_and_fileName(file2feature)[1])\n",
    "            if(model == \"rdf\"):\n",
    "                # NOTE: If you change the position or the name of the feature generator change the\n",
    "                # next string \"cmd2feature\" [execution command]\n",
    "                cmd2features = \"./pcl/build/my_feature %s %.3f %s %s\" %(\"fpfh\",          # Feature extractor \n",
    "                                                                        0.025,           # Grid size \n",
    "                                                                        file2feature,    # Input File\n",
    "                                                                        file2wrt)        # Output File\n",
    "                print(\" -> Running feature extractor\")\n",
    "                os.system(cmd2features)\n",
    "            else: # RandLA-NET\n",
    "                if(folderName==\"test\"):\n",
    "                    convert_for_test(file2feature, path2saveData, grid_size=0.001, protocol=protocol)\n",
    "                else:\n",
    "                    convert_for_training(file2feature, None, path2saveData, grid_size=0.001, protocol=protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-brand",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-supply",
   "metadata": {},
   "source": [
    "## RandLA-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "from randlanet.main_apple_tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2data_rnet = \"data/annotated_apples_noRadiometric/\"  # Data to predict\n",
    "path2model_rnet= \"data/trained_model_randlanet/snapshots_only_xyz/snap-9001\" # Trained model \n",
    "dataReady      = False # If the data is on txt format set as true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-> Input path: %s\" %(\"Not found\" if not os.path.isdir(path2data_rnet) else \"OK\" ) )\n",
    "print(\"-> Model path: %s\" %(\"Not found\" if not os.path.isdir(path2model_rnet) else \"OK\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not dataReady):\n",
    "    dataSet(path2data_rnet, path2data_rnet, \"rnet\", verbose=False, protocol=\"field_only_xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for the model\n",
    "param = {\"gpu\":0, # -1 no GPU\n",
    "         \"model_path\":path2model_rnet, \n",
    "         \"path2data\":path2data_rnet, \n",
    "         \"path2output\": \"./\", # This arg only works to save the training \n",
    "         \"protocol\":\"field_only_xyz\", \n",
    "         \"trainFromCHK\":False}  \n",
    "# NOTE: Ensure that the subsampling points in the training are the same for the prediction[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "randlanet_predict(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge labels \n",
    "# NOTE: RandLA-NET write the probabilities and the labels of each point cloud on different files, \n",
    "# To visualize the classification the predicted classes and the point cloud are going to be merged \n",
    "from randlanet.utils.merge_label_apple import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2prediction = \"test/Log_XXXXX/predictions/\" # The name of the folder always is \n",
    "                                                # going to change with the date\n",
    "path2data = os.path.join(param[\"path2data\"],\"test/\")\n",
    "OutputPath = os.path.join(path2data, \"merged/\")\n",
    "\n",
    "merge_pointCloudAndLabels(path2data, \"./test/\", OutputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-payday",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning.predict import predict \n",
    "from machine_learning.RFClassifier import RFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFClassifier\n",
    "model_weights = \"data/example2notebook_realdata/model_rf.sav\"\n",
    "path2data = \"data/example2notebook_realdata/dataToRDF/test/\"\n",
    "OutputPath = os.path.join(path2data, \"prediction/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, model_weights, path2data, path2output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-investigator",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import numpy as np \n",
    "import sklearn.cluster\n",
    "from post_processing.algorithm import clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_annApples = glob.glob(os.path.join(OutputPath,\"*.txt\"))\n",
    "path2wrt = os.path.join(OutputPath,\"clusters/\")\n",
    "\n",
    "if(not os.path.join(path2wrt)):\n",
    "    os.mkdir(path2wrt)\n",
    "\n",
    "eps, minSamples = 0.1, 20 # 0.4, 20 funciona pero consume mucha memoria \n",
    "\n",
    "print(\"Found annotated files: %i\" %(len(files_annApples)))\n",
    "\n",
    "for idx, file2clustering in enumerate(files_annApples, start=1):\n",
    "    _, actualFileName = split_path_and_fileName(file2clustering)\n",
    "    print(\"-> Loading[%i/%i]: %s\" %(len(files_annApples), idx, actualFileName))\n",
    "    pointCloud2cluster = np.loadtxt(file2clustering)\n",
    "    cluster = clustering(pointCloud2cluster, minSamples, eps)\n",
    "    print(\" -> The file will be written in: %s\" %path2wrt)\n",
    "    np.savetxt(path2wrt+actualFileName, cluster)# The cluster is in the last column of the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
